{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO6LzGvDEXYRKkeXI1pxn2o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RubhavSaini/G_colab/blob/main/Prj_stockmrk_pred.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGkRBI_h-Xqz",
        "outputId": "12c3fad8-47a0-4b85-c9a2-692395a555bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.11/dist-packages (0.2.65)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (3.0.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.5.1)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.0.2)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.32.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance) (0.0.12)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.3.8)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2025.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.11/dist-packages (from yfinance) (3.18.2)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.13.4)\n",
            "Requirement already satisfied: curl_cffi>=0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance) (0.12.0)\n",
            "Requirement already satisfied: protobuf>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (5.29.5)\n",
            "Requirement already satisfied: websockets>=13.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (15.0.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.74.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.7)\n",
            "Requirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from curl_cffi>=0.7->yfinance) (1.17.1)\n",
            "Requirement already satisfied: certifi>=2024.2.2 in /usr/local/lib/python3.11/dist-packages (from curl_cffi>=0.7->yfinance) (2025.7.14)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (2.5.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install yfinance scikit-learn xgboost tensorflow joblib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GRU, LSTM, Bidirectional, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n"
      ],
      "metadata": {
        "id": "v8w1ep7f-v_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ta"
      ],
      "metadata": {
        "id": "3bmkO_38A7MU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sequences(data, time_step=60):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - time_step):\n",
        "        X.append(data[i:i + time_step])\n",
        "        y.append(data[i + time_step][0])\n",
        "    return np.array(X), np.array(y)"
      ],
      "metadata": {
        "id": "hid1OY8u-0a1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(name, y_true, y_pred):\n",
        "  non_zero_idx = y_true != 0\n",
        "    safe_y_true = y_true[non_zero_idx]\n",
        "    safe_y_pred = y_pred[non_zero_idx]\n",
        "\n",
        "    mape = np.mean(np.abs((safe_y_true - safe_y_pred) / safe_y_true)) * 100\n",
        "\n",
        "    return {\n",
        "        \"model\": model_name,\n",
        "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
        "        \"MSE\": mean_squared_error(y_true, y_pred),\n",
        "        \"RMSE\": np.sqrt(mean_squared_error(y_true, y_pred)),\n",
        "        \"R2\": r2_score(y_true, y_pred),\n",
        "        \"MAPE\": mape\n",
        "    }\n"
      ],
      "metadata": {
        "id": "jhCVE5N1--3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_save_all_models(ticker):\n",
        "    df = yf.download(ticker, start=\"2015-01-01\", end=\"2025-06-30\")\n",
        "    df = df[['Open', 'High', 'Low', 'Close', 'Volume']].dropna()\n",
        "\n",
        "   # Calculate indicators\n",
        "    close_series = df['Close'].squeeze()\n",
        "    df['RSI'] = ta.momentum.RSIIndicator(close=close_series, window=14).rsi()\n",
        "    df['SMA'] = ta.trend.SMAIndicator(close=close_series, window=20).sma_indicator()\n",
        "    df['EMA'] = ta.trend.EMAIndicator(close=close_series, window=20).ema_indicator()\n",
        "    macd = ta.trend.MACD(close=close_series)\n",
        "    df['MACD'] = macd.macd()\n",
        "    df['MACD_signal'] = macd.macd_signal()\n",
        "    df['MACD_diff'] = macd.macd_diff()\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "   # Select the 7 features\n",
        "    feature_cols = ['Close', 'RSI', 'SMA', 'EMA', 'MACD', 'MACD_signal', 'MACD_diff']\n",
        "    df = df[feature_cols]\n",
        "\n",
        "  #  # Scale and reshape\n",
        "  #   scaler = MinMaxScaler()\n",
        "  #   scaled = scaler.fit_transform(df)\n",
        "\n",
        "  #   X, y = create_sequences(scaled)\n",
        "  #   X = X.reshape(X.shape[0], X.shape[1], len(feature_cols))\n",
        "\n",
        "  #   train_size = int(len(X)*0.8)\n",
        "  #   X_train, X_test = X[:train_size], X[train_size:]\n",
        "  #   y_train, y_test = y[:train_size], y[train_size:]\n",
        "\n",
        "  #   X_flat_train = X_train.reshape(X_train.shape[0], -1)\n",
        "  #   X_flat_test = X_test.reshape(X_test.shape[0], -1)\n",
        "\n",
        "  #   results = []\n",
        "  #   early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "  #   # GRU\n",
        "  #   model_gru = Sequential([\n",
        "  #   GRU(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "\n",
        "  #   Dropout(0.2), GRU(50), Dropout(0.2), Dense(1)])\n",
        "  #   model_gru.compile(optimizer='adam', loss='mean_squared_error')\n",
        "  #   model_gru.summary()\n",
        "  #   model_gru.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stop], verbose=0)\n",
        "  #   y_pred_gru = scaler.inverse_transform(model_gru.predict(X_test))\n",
        "  #   y_test_rescaled = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
        "  #   results.append({\"ticker\": ticker, **evaluate_model(\"GRU\", y_test_rescaled, y_pred_gru)})\n",
        "  #   model_gru.save(f\"{ticker.split('.')[0].lower()}_gru.h5\")\n",
        "  #   # model_gru.save(f\"{ticker.split('.')[0].lower()}_gru.h5\")\n",
        "\n",
        "  #   # LSTM\n",
        "  #   model_lstm = Sequential([\n",
        "  #   LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "  #   Dropout(0.2), LSTM(50), Dropout(0.2), Dense(1)])\n",
        "  #   model_lstm.compile(optimizer='adam', loss='mean_squared_error')\n",
        "  #   model_lstm.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stop], verbose=0)\n",
        "  #   y_pred_lstm = scaler.inverse_transform(model_lstm.predict(X_test))\n",
        "  #   results.append({\"ticker\": ticker, **evaluate_model(\"LSTM\", y_test_rescaled, y_pred_lstm)})\n",
        "\n",
        "  #   # BiLSTM\n",
        "  #   model_bilstm = Sequential([\n",
        "  #   Bidirectional(LSTM(50, return_sequences=True), input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "  #   Dropout(0.2), Bidirectional(LSTM(50)), Dropout(0.2), Dense(1)])\n",
        "  #   model_bilstm.compile(optimizer='adam', loss='mean_squared_error')\n",
        "  #   model_bilstm.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stop], verbose=0)\n",
        "  #   y_pred_bilstm = scaler.inverse_transform(model_bilstm.predict(X_test))\n",
        "  #   results.append({\"ticker\": ticker, **evaluate_model(\"BiLSTM\", y_test_rescaled, y_pred_bilstm)})\n",
        "\n",
        "  #   # Random Forest\n",
        "  #   rf = RandomForestRegressor()\n",
        "  #   rf.fit(X_flat_train, y_train)\n",
        "  #   y_pred_rf = scaler.inverse_transform(rf.predict(X_flat_test).reshape(-1, 1))\n",
        "  #   results.append({\"ticker\": ticker, **evaluate_model(\"Random Forest\", y_test_rescaled, y_pred_rf)})\n",
        "\n",
        "  #   # XGBoost\n",
        "  #   xgb = XGBRegressor()\n",
        "  #   xgb.fit(X_flat_train, y_train)\n",
        "  #   y_pred_xgb = scaler.inverse_transform(xgb.predict(X_flat_test).reshape(-1, 1))\n",
        "  #   results.append({\"ticker\": ticker, **evaluate_model(\"XGBoost\", y_test_rescaled, y_pred_xgb)})\n",
        "\n",
        "  #   return results\n",
        "\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    scaled_data = scaler.fit_transform(df)\n",
        "    sequence_length = 60\n",
        "    X, y = [], []\n",
        "    for i in range(sequence_length, len(scaled_data)):\n",
        "        X.append(scaled_data[i-sequence_length:i])\n",
        "        y.append(scaled_data[i, 0])  # Predict 'Close'\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    # Train-test split\n",
        "    split = int(0.8 * len(X))\n",
        "    X_train, X_test = X[:split], X[split:]\n",
        "    y_train, y_test = y[:split], y[split:]\n",
        "\n",
        "    # Flatten for RF and XGBoost\n",
        "    X_flat_train = X_train.reshape(X_train.shape[0], -1)\n",
        "    X_flat_test = X_test.reshape(X_test.shape[0], -1)\n",
        "\n",
        "    # Rescale y_test for metrics\n",
        "    y_test_rescaled = scaler.inverse_transform(\n",
        "        np.concatenate([np.zeros((len(y_test), df.shape[1]-1)), y_test.reshape(-1, 1)], axis=1)\n",
        "    )[:, -1]\n",
        "\n",
        "    results = []\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "    # GRU\n",
        "    model_gru = Sequential([\n",
        "        GRU(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "        Dropout(0.2),\n",
        "        GRU(50),\n",
        "        Dropout(0.2),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    model_gru.compile(optimizer='adam', loss='mean_squared_error')\n",
        "    model_gru.fit(X_train, y_train, epochs=20, batch_size=32,\n",
        "                  validation_data=(X_test, y_test), callbacks=[early_stop], verbose=0)\n",
        "    y_pred_gru = model_gru.predict(X_test)\n",
        "    y_pred_gru = scaler.inverse_transform(\n",
        "        np.concatenate([np.zeros((len(y_pred_gru), df.shape[1]-1)), y_pred_gru], axis=1)\n",
        "    )[:, -1]\n",
        "    results.append({\"ticker\": ticker, **evaluate_model(\"GRU\", y_test_rescaled, y_pred_gru)})\n",
        "    model_gru.save(f\"{ticker.split('.')[0].lower()}_gru.h5\")\n",
        "\n",
        "    # LSTM\n",
        "    model_lstm = Sequential([\n",
        "        LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "        Dropout(0.2),\n",
        "        LSTM(50),\n",
        "        Dropout(0.2),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    model_lstm.compile(optimizer='adam', loss='mean_squared_error')\n",
        "    model_lstm.fit(X_train, y_train, epochs=20, batch_size=32,\n",
        "                   validation_data=(X_test, y_test), callbacks=[early_stop], verbose=0)\n",
        "    y_pred_lstm = model_lstm.predict(X_test)\n",
        "    y_pred_lstm = scaler.inverse_transform(\n",
        "        np.concatenate([np.zeros((len(y_pred_lstm), df.shape[1]-1)), y_pred_lstm], axis=1)\n",
        "    )[:, -1]\n",
        "    results.append({\"ticker\": ticker, **evaluate_model(\"LSTM\", y_test_rescaled, y_pred_lstm)})\n",
        "    # model_lstm.save(f\"{ticker.split('.')[0].lower()}_lstm.h5\")\n",
        "\n",
        "    # BiLSTM\n",
        "    model_bilstm = Sequential([\n",
        "        Bidirectional(LSTM(50, return_sequences=True), input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "        Dropout(0.2),\n",
        "        Bidirectional(LSTM(50)),\n",
        "        Dropout(0.2),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    model_bilstm.compile(optimizer='adam', loss='mean_squared_error')\n",
        "    model_bilstm.fit(X_train, y_train, epochs=20, batch_size=32,\n",
        "                     validation_data=(X_test, y_test), callbacks=[early_stop], verbose=0)\n",
        "    y_pred_bilstm = model_bilstm.predict(X_test)\n",
        "    y_pred_bilstm = scaler.inverse_transform(\n",
        "        np.concatenate([np.zeros((len(y_pred_bilstm), df.shape[1]-1)), y_pred_bilstm], axis=1)\n",
        "    )[:, -1]\n",
        "    results.append({\"ticker\": ticker, **evaluate_model(\"BiLSTM\", y_test_rescaled, y_pred_bilstm)})\n",
        "    # model_bilstm.save(f\"{ticker.split('.')[0].lower()}_bilstm.h5\")\n",
        "\n",
        "    # Random Forest\n",
        "    rf = RandomForestRegressor()\n",
        "    rf.fit(X_flat_train, y_train)\n",
        "    y_pred_rf = rf.predict(X_flat_test)\n",
        "    y_pred_rf = scaler.inverse_transform(\n",
        "        np.concatenate([np.zeros((len(y_pred_rf), df.shape[1]-1)), y_pred_rf.reshape(-1, 1)], axis=1)\n",
        "    )[:, -1]\n",
        "    results.append({\"ticker\": ticker, **evaluate_model(\"Random Forest\", y_test_rescaled, y_pred_rf)})\n",
        "\n",
        "    # XGBoost\n",
        "    xgb = XGBRegressor()\n",
        "    xgb.fit(X_flat_train, y_train)\n",
        "    y_pred_xgb = xgb.predict(X_flat_test)\n",
        "    y_pred_xgb = scaler.inverse_transform(\n",
        "        np.concatenate([np.zeros((len(y_pred_xgb), df.shape[1]-1)), y_pred_xgb.reshape(-1, 1)], axis=1)\n",
        "    )[:, -1]\n",
        "    results.append({\"ticker\": ticker, **evaluate_model(\"XGBoost\", y_test_rescaled, y_pred_xgb)})\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "WqiOtbL1_LHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def train_and_save_all_models(ticker):\n",
        "#     df = yf.download(ticker, start=\"2015-01-01\", end=\"2025-6-30\")\n",
        "#     df = df[['Close']].dropna()\n",
        "#     scaler = MinMaxScaler()\n",
        "#     scaled = scaler.fit_transform(df)\n",
        "\n",
        "#     X, y = create_sequences(scaled)\n",
        "#     X = X.reshape(X.shape[0], X.shape[1], 1)\n",
        "#     train_size = int(len(X)*0.8)\n",
        "#     X_train, X_test = X[:train_size], X[train_size:]\n",
        "#     y_train, y_test = y[:train_size], y[train_size:]\n",
        "\n",
        "#     X_flat_train = X_train.reshape(X_train.shape[0], -1)\n",
        "#     X_flat_test = X_test.reshape(X_test.shape[0], -1)\n",
        "\n",
        "#     results = []\n",
        "\n",
        "#     # GRU\n",
        "#     model_gru = Sequential([\n",
        "#     GRU(50, return_sequences=True, input_shape=(X_train.shape[1], 1)),\n",
        "#     Dropout(0.2), GRU(50), Dropout(0.2), Dense(1)])\n",
        "#     model_gru.compile(optimizer='adam', loss='mean_squared_error')\n",
        "#     model_gru.summary()\n",
        "#     model_gru.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test), verbose=0)\n",
        "#     y_pred_gru = scaler.inverse_transform(model_gru.predict(X_test))\n",
        "#     y_test_rescaled = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
        "#     results.append({\"ticker\": ticker, **evaluate_model(\"GRU\", y_test_rescaled, y_pred_gru)})\n",
        "#     model_gru.save(f\"{ticker.split('.')[0].lower()}_gru.h5\")\n",
        "#  # LSTM\n",
        "#     model_lstm = Sequential([\n",
        "#     LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], 1)),\n",
        "#     Dropout(0.2), LSTM(50), Dropout(0.2), Dense(1)])\n",
        "#     model_lstm.compile(optimizer='adam', loss='mean_squared_error')\n",
        "#     model_lstm.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test), verbose=0)\n",
        "#     y_pred_lstm = scaler.inverse_transform(model_lstm.predict(X_test))\n",
        "#     results.append({\"ticker\": ticker, **evaluate_model(\"LSTM\", y_test_rescaled, y_pred_lstm)})\n",
        "\n",
        "#     # BiLSTM\n",
        "#     model_bilstm = Sequential([\n",
        "#     Bidirectional(LSTM(50, return_sequences=True), input_shape=(X_train.shape[1], 1)),\n",
        "#     Dropout(0.2), Bidirectional(LSTM(50)), Dropout(0.2), Dense(1)])\n",
        "#     model_bilstm.compile(optimizer='adam', loss='mean_squared_error')\n",
        "#     model_bilstm.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test), verbose=0)\n",
        "#     y_pred_bilstm = scaler.inverse_transform(model_bilstm.predict(X_test))\n",
        "#     results.append({\"ticker\": ticker, **evaluate_model(\"BiLSTM\", y_test_rescaled, y_pred_bilstm)})\n",
        "\n",
        "#     # Random Forest\n",
        "#     rf = RandomForestRegressor()\n",
        "#     rf.fit(X_flat_train, y_train)\n",
        "#     y_pred_rf = scaler.inverse_transform(rf.predict(X_flat_test).reshape(-1, 1))\n",
        "#     results.append({\"ticker\": ticker, **evaluate_model(\"Random Forest\", y_test_rescaled, y_pred_rf)})\n",
        "\n",
        "#     # XGBoost\n",
        "#     xgb = XGBRegressor()\n",
        "#     xgb.fit(X_flat_train, y_train)\n",
        "#     y_pred_xgb = scaler.inverse_transform(xgb.predict(X_flat_test).reshape(-1, 1))\n",
        "#     results.append({\"ticker\": ticker, **evaluate_model(\"XGBoost\", y_test_rescaled, y_pred_xgb)})\n",
        "\n",
        "#     return results\n"
      ],
      "metadata": {
        "id": "_vM9GMKB_L2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stocks = [\"RELIANCE.NS\", \"TCS.NS\", \"ADANIPORTS.NS\", \"INFY.NS\", \"ITC.NS\"]\n",
        "all_results = []\n",
        "for stock in stocks:\n",
        "    all_results += train_and_save_all_models(stock)\n",
        "\n",
        "df = pd.DataFrame(all_results)\n",
        "df.to_csv(\"all_model_results.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxiAm1t6_Lyz",
        "outputId": "73e9cc4c-ec5a-44b2-f4b5-9e63b9ec6910"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-269152351.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  df = yf.download(ticker, start=\"2015-01-01\", end=\"2025-06-30\")\n",
            "\r[*********************100%***********************]  1 of 1 completed\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-269152351.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  df = yf.download(ticker, start=\"2015-01-01\", end=\"2025-06-30\")\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-269152351.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  df = yf.download(ticker, start=\"2015-01-01\", end=\"2025-06-30\")\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-269152351.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  df = yf.download(ticker, start=\"2015-01-01\", end=\"2025-06-30\")\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-269152351.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  df = yf.download(ticker, start=\"2015-01-01\", end=\"2025-06-30\")\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "metadata": {
        "id": "DEI4elDF_Lwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile(\"models.zip\", \"w\") as zipf:\n",
        "    for ticker in stocks:\n",
        "        zipf.write(f\"{ticker.split('.')[0].lower()}_gru.h5\")\n",
        "    zipf.write(\"all_model_results.csv\")"
      ],
      "metadata": {
        "id": "MiCAs1KV_Lt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# zipf.open(\"models.zip\")"
      ],
      "metadata": {
        "id": "T6ZPGsDRLNQ-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "bb442016-3b8a-42af-930e-5be7a2c55af4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Attempt to use ZIP archive that was already closed",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-606345462.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mzipf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"models.zip\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.11/zipfile.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, name, mode, pwd, force_zip64)\u001b[0m\n\u001b[1;32m   1549\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pwd is only supported for reading files\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1551\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1552\u001b[0m                 \"Attempt to use ZIP archive that was already closed\")\n\u001b[1;32m   1553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Attempt to use ZIP archive that was already closed"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"models.zip\")"
      ],
      "metadata": {
        "id": "whz5Awp0BFeD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "8cf99bb9-b968-424f-f52d-0967f5da060f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6c3d457d-7b5d-4c7a-b3f2-c1866aa1e211\", \"models.zip\", 1656723)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_model_results.csv"
      ],
      "metadata": {
        "id": "X3uh0D4Cm1_X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "aa16f412-aad0-4f8c-ea4b-c11a331b0920"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'all_model_results' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1920781050.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_model_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'all_model_results' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ibNanK2uD7RD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}